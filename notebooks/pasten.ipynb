{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-14T05:59:09.266326922Z",
     "start_time": "2023-10-14T05:59:04.965197124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\r\n",
      "  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/1e/2c/af22cd797fc368a9f098ed03015730e6568b884fe67f9940793d944a4b7b/bitsandbytes-0.41.1-py3-none-any.whl.metadata\r\n",
      "  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\r\n",
      "Using cached bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\r\n",
      "Installing collected packages: bitsandbytes\r\n",
      "Successfully installed bitsandbytes-0.41.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "codellama/CodeLlama-7b-Instruct-hf does not appear to have a file named config.json. Checkout 'https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load model directly\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001B[0;32m----> 4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mAutoTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcodellama/CodeLlama-7b-Instruct-hf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcodellama/CodeLlama-7b-Instruct-hf\u001B[39m\u001B[38;5;124m\"\u001B[39m, load_in_8bit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:716\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config_tokenizer_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    715\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[0;32m--> 716\u001B[0m         config \u001B[38;5;241m=\u001B[39m \u001B[43mAutoConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    717\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    718\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    719\u001B[0m     config_tokenizer_class \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mtokenizer_class\n\u001B[1;32m    720\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoTokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39mauto_map:\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1034\u001B[0m, in \u001B[0;36mAutoConfig.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m   1031\u001B[0m trust_remote_code \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrust_remote_code\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1032\u001B[0m code_revision \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_revision\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1034\u001B[0m config_dict, unused_kwargs \u001B[38;5;241m=\u001B[39m \u001B[43mPretrainedConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_config_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1035\u001B[0m has_remote_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1036\u001B[0m has_local_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m CONFIG_MAPPING\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:620\u001B[0m, in \u001B[0;36mPretrainedConfig.get_config_dict\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    618\u001B[0m original_kwargs \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(kwargs)\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_config_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict:\n\u001B[1;32m    622\u001B[0m     original_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:675\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    671\u001B[0m configuration_file \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_configuration_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, CONFIG_NAME)\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfiguration_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    686\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    687\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    689\u001B[0m     commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n\u001B[1;32m    691\u001B[0m     \u001B[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001B[39;00m\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;66;03m# the original exception.\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:400\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(resolved_file):\n\u001B[1;32m    399\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _raise_exceptions_for_missing_entries:\n\u001B[0;32m--> 400\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    401\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Checkout \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    402\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available files.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    403\u001B[0m         )\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: codellama/CodeLlama-7b-Instruct-hf does not appear to have a file named config.json. Checkout 'https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf/None' for available files."
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\", load_in_8bit=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:12:13.267085074Z",
     "start_time": "2023-10-14T06:12:12.420580008Z"
    }
   },
   "id": "1aa6297c08a59187"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": "('codellama/CodeLlama-7b-Instruct-hf/tokenizer/tokenizer_config.json',\n 'codellama/CodeLlama-7b-Instruct-hf/tokenizer/special_tokens_map.json',\n 'codellama/CodeLlama-7b-Instruct-hf/tokenizer/tokenizer.model',\n 'codellama/CodeLlama-7b-Instruct-hf/tokenizer/added_tokens.json',\n 'codellama/CodeLlama-7b-Instruct-hf/tokenizer/tokenizer.json')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('codellama/CodeLlama-7b-Instruct-hf/tokenizer')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:08:51.054403844Z",
     "start_time": "2023-10-14T06:08:50.945152265Z"
    }
   },
   "id": "9b185c1a92f4d753"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model.save_pretrained('codellama/CodeLlama-7b-Instruct-hf/model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:11:23.098322002Z",
     "start_time": "2023-10-14T06:09:05.772475421Z"
    }
   },
   "id": "c03d0a3effc33b64"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "del model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:12:00.685947112Z",
     "start_time": "2023-10-14T06:12:00.660565905Z"
    }
   },
   "id": "9d342e321ba36ea5"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "TheBloke/CodeLlama-7B-Instruct-GGUF does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTheBloke/CodeLlama-7B-Instruct-GGUF\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcodellama-7b-instruct.q4_K_M.gguf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mllama\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# print(llm(\"AI is going to\"))\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:565\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    564\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m--> 565\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    571\u001B[0m )\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:2970\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   2964\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m   2965\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2966\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m but there is a file without the variant\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2967\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvariant\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Use `variant=None` to load this model from those weights.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2968\u001B[0m             )\n\u001B[1;32m   2969\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2970\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m   2971\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2972\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF2_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2973\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mFLAX_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2974\u001B[0m             )\n\u001B[1;32m   2975\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n\u001B[1;32m   2976\u001B[0m     \u001B[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\u001B[39;00m\n\u001B[1;32m   2977\u001B[0m     \u001B[38;5;66;03m# to the original exception.\u001B[39;00m\n\u001B[1;32m   2978\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: TheBloke/CodeLlama-7B-Instruct-GGUF does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
     ]
    }
   ],
   "source": [
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/CodeLlama-7B-Instruct-GGUF\", model_file=\"codellama-7b-instruct.q4_K_M.gguf\", model_type=\"llama\", gpu_layers=0)\n",
    "\n",
    "# print(llm(\"AI is going to\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:15:49.647982400Z",
     "start_time": "2023-10-14T06:15:48.486635055Z"
    }
   },
   "id": "4f530a0fdab61a51"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-gptq\r\n",
      "  Obtaining dependency information for auto-gptq from https://files.pythonhosted.org/packages/38/d3/f404ee986f2e1f9fa744296365b0bfbbf3d3a779a2b2dc92e54e919ca297/auto_gptq-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading auto_gptq-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n",
      "Collecting accelerate>=0.19.0 (from auto-gptq)\r\n",
      "  Obtaining dependency information for accelerate>=0.19.0 from https://files.pythonhosted.org/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl.metadata\r\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: datasets in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from auto-gptq) (2.14.5)\r\n",
      "Requirement already satisfied: numpy in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from auto-gptq) (1.25.2)\r\n",
      "Collecting rouge (from auto-gptq)\r\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from auto-gptq) (2.0.1+cu118)\r\n",
      "Requirement already satisfied: safetensors in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from auto-gptq) (0.3.3)\r\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from auto-gptq) (4.34.0)\r\n",
      "Collecting peft (from auto-gptq)\r\n",
      "  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/37/1a/8d20e8704da9fa070eb909265584b960da57be1d833d550c59f50906dc5c/peft-0.5.0-py3-none-any.whl.metadata\r\n",
      "  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from accelerate>=0.19.0->auto-gptq) (23.1)\r\n",
      "Requirement already satisfied: psutil in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from accelerate>=0.19.0->auto-gptq) (5.9.5)\r\n",
      "Requirement already satisfied: pyyaml in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from accelerate>=0.19.0->auto-gptq) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from accelerate>=0.19.0->auto-gptq) (0.16.4)\r\n",
      "Requirement already satisfied: filelock in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.13.0->auto-gptq) (3.12.4)\r\n",
      "Requirement already satisfied: typing-extensions in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.13.0->auto-gptq) (4.8.0)\r\n",
      "Requirement already satisfied: sympy in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\r\n",
      "Requirement already satisfied: networkx in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.13.0->auto-gptq) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\r\n",
      "Requirement already satisfied: triton==2.0.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\r\n",
      "Requirement already satisfied: cmake in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (3.25.0)\r\n",
      "Requirement already satisfied: lit in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (15.0.7)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers>=4.31.0->auto-gptq) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers>=4.31.0->auto-gptq) (0.14.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers>=4.31.0->auto-gptq) (4.66.1)\r\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->auto-gptq) (13.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->auto-gptq) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->auto-gptq) (2.1.1)\r\n",
      "Requirement already satisfied: xxhash in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->auto-gptq) (3.3.0)\r\n",
      "Requirement already satisfied: multiprocess in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->auto-gptq) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->auto-gptq) (2023.6.0)\r\n",
      "Requirement already satisfied: aiohttp in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->auto-gptq) (3.8.5)\r\n",
      "Requirement already satisfied: six in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from rouge->auto-gptq) (1.16.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->auto-gptq) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.5)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from pandas->datasets->auto-gptq) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from pandas->datasets->auto-gptq) (2023.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\r\n",
      "Downloading auto_gptq-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m0m\r\n",
      "\u001B[?25hDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m258.1/258.1 kB\u001B[0m \u001B[31m40.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading peft-0.5.0-py3-none-any.whl (85 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.6/85.6 kB\u001B[0m \u001B[31m28.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: rouge, accelerate, peft, auto-gptq\r\n",
      "Successfully installed accelerate-0.23.0 auto-gptq-0.4.2 peft-0.5.0 rouge-1.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install auto-gptq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:20:01.863909983Z",
     "start_time": "2023-10-14T06:19:55.093554149Z"
    }
   },
   "id": "bc59144a1df9ec4c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('/etc/xdg/xdg-ubuntu')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('gnome-shell/PyCharm Professional Edition/2712-5-jacob-pc_TIME11487650')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('local/jacob-pc'), PosixPath('@/tmp/.ICE-unix/2687,unix/jacob-pc')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('1'), PosixPath('0')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//debuginfod.ubuntu.com ')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('notebooks/pasten.ipynb')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=118, Highest Compute Capability: 7.5.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
      "libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m model_name_or_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTheBloke/CodeLlama-7B-GPTQ\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# To use a different branch, change revision\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# For example: revision=\"main\"\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                                             \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                                             \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                                             \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:560\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    558\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    559\u001B[0m         \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mregister(config\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, model_class, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 560\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    561\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    562\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    564\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:2713\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   2708\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m   2709\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need a version of auto_gptq >= 0.4.2 to use GPTQ: `pip install --upgrade auto-gptq`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2710\u001B[0m     )\n\u001B[1;32m   2711\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2712\u001B[0m     \u001B[38;5;66;03m# Need to protect the import\u001B[39;00m\n\u001B[0;32m-> 2713\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01moptimum\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgptq\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GPTQQuantizer\n\u001B[1;32m   2714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m quantization_method_from_config \u001B[38;5;241m==\u001B[39m QuantizationMethod\u001B[38;5;241m.\u001B[39mGPTQ:\n\u001B[1;32m   2715\u001B[0m     quantization_config \u001B[38;5;241m=\u001B[39m GPTQConfig\u001B[38;5;241m.\u001B[39mfrom_dict(config\u001B[38;5;241m.\u001B[39mquantization_config)\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/optimum/gptq/__init__.py:15\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# coding=utf-8\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Copyright 2023 HuggingFace Inc. team.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquantizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GPTQQuantizer, load_quantized_model\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/optimum/gptq/quantizer.py:44\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maccelerate\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhooks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m remove_hook_from_module\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_auto_gptq_available():\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauto_gptq\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m exllama_set_max_input_length\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauto_gptq\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autogptq_post_init\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mauto_gptq\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquantization\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GPTQ\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/auto_gptq/__init__.py:4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseQuantizeConfig\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoGPTQForCausalLM\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpeft_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_gptq_peft_model\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexllama_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m exllama_set_max_input_length\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/auto_gptq/utils/peft_utils.py:9\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List, Optional\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpeft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_peft_model, PeftConfig, PeftModel, PeftType\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpeft\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpeft_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PEFT_TYPE_TO_MODEL_MAPPING\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpeft\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlora\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoraConfig, LoraLayer, LoraModel, Embedding\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/peft/__init__.py:22\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# flake8: noqa\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.5.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     23\u001B[0m     AutoPeftModel,\n\u001B[1;32m     24\u001B[0m     AutoPeftModelForCausalLM,\n\u001B[1;32m     25\u001B[0m     AutoPeftModelForSequenceClassification,\n\u001B[1;32m     26\u001B[0m     AutoPeftModelForSeq2SeqLM,\n\u001B[1;32m     27\u001B[0m     AutoPeftModelForTokenClassification,\n\u001B[1;32m     28\u001B[0m     AutoPeftModelForQuestionAnswering,\n\u001B[1;32m     29\u001B[0m     AutoPeftModelForFeatureExtraction,\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmapping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     32\u001B[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001B[1;32m     33\u001B[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m     inject_adapter_in_model,\n\u001B[1;32m     37\u001B[0m )\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpeft_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     39\u001B[0m     PeftModel,\n\u001B[1;32m     40\u001B[0m     PeftModelForCausalLM,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m     PeftModelForFeatureExtraction,\n\u001B[1;32m     46\u001B[0m )\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/peft/auto.py:31\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     22\u001B[0m     AutoModel,\n\u001B[1;32m     23\u001B[0m     AutoModelForCausalLM,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     27\u001B[0m     AutoModelForTokenClassification,\n\u001B[1;32m     28\u001B[0m )\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PeftConfig\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmapping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpeft_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     33\u001B[0m     PeftModel,\n\u001B[1;32m     34\u001B[0m     PeftModelForCausalLM,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     39\u001B[0m     PeftModelForTokenClassification,\n\u001B[1;32m     40\u001B[0m )\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01m_BaseAutoPeftModel\u001B[39;00m:\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/peft/mapping.py:23\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PeftConfig\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpeft_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     24\u001B[0m     PeftModel,\n\u001B[1;32m     25\u001B[0m     PeftModelForCausalLM,\n\u001B[1;32m     26\u001B[0m     PeftModelForFeatureExtraction,\n\u001B[1;32m     27\u001B[0m     PeftModelForQuestionAnswering,\n\u001B[1;32m     28\u001B[0m     PeftModelForSeq2SeqLM,\n\u001B[1;32m     29\u001B[0m     PeftModelForSequenceClassification,\n\u001B[1;32m     30\u001B[0m     PeftModelForTokenClassification,\n\u001B[1;32m     31\u001B[0m )\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     33\u001B[0m     AdaLoraConfig,\n\u001B[1;32m     34\u001B[0m     AdaLoraModel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m     PromptTuningConfig,\n\u001B[1;32m     43\u001B[0m )\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _prepare_prompt_learning_config\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/peft/peft_model.py:38\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PeftConfig\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     39\u001B[0m     AdaLoraModel,\n\u001B[1;32m     40\u001B[0m     AdaptionPromptModel,\n\u001B[1;32m     41\u001B[0m     IA3Model,\n\u001B[1;32m     42\u001B[0m     LoraModel,\n\u001B[1;32m     43\u001B[0m     PrefixEncoder,\n\u001B[1;32m     44\u001B[0m     PromptEmbedding,\n\u001B[1;32m     45\u001B[0m     PromptEncoder,\n\u001B[1;32m     46\u001B[0m )\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     48\u001B[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001B[1;32m     49\u001B[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     62\u001B[0m     shift_tokens_right,\n\u001B[1;32m     63\u001B[0m )\n\u001B[1;32m     66\u001B[0m PEFT_TYPE_TO_MODEL_MAPPING \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     67\u001B[0m     PeftType\u001B[38;5;241m.\u001B[39mLORA: LoraModel,\n\u001B[1;32m     68\u001B[0m     PeftType\u001B[38;5;241m.\u001B[39mPROMPT_TUNING: PromptEmbedding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     73\u001B[0m     PeftType\u001B[38;5;241m.\u001B[39mIA3: IA3Model,\n\u001B[1;32m     74\u001B[0m }\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/peft/tuners/__init__.py:21\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# flake8: noqa\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madaption_prompt\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AdaptionPromptConfig, AdaptionPromptModel\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlora\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LoraConfig, LoraModel\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mia3\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IA3Config, IA3Model\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madalora\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AdaLoraConfig, AdaLoraModel\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/peft/tuners/lora.py:45\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtuners_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseTuner, BaseTunerLayer\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_bnb_available():\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mbnb\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;129m@dataclass\u001B[39m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mLoraConfig\u001B[39;00m(PeftConfig):\n\u001B[1;32m     50\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;124;03m    This is the configuration class to store the configuration of a [`LoraModel`].\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;124;03m            pattern is not in the common layers pattern.\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/bitsandbytes/__init__.py:6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# This source code is licensed under the MIT license found in the\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cuda_setup, utils, research\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_functions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      8\u001B[0m     MatmulLtState,\n\u001B[1;32m      9\u001B[0m     bmm_cublas,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m     matmul_4bit\n\u001B[1;32m     14\u001B[0m )\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m COMPILED_WITH_CUDA\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/bitsandbytes/research/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_functions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      3\u001B[0m     switchback_bnb,\n\u001B[1;32m      4\u001B[0m     matmul_fp8_global,\n\u001B[1;32m      5\u001B[0m     matmul_fp8_mixed,\n\u001B[1;32m      6\u001B[0m )\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/bitsandbytes/research/nn/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/bitsandbytes/research/nn/modules.py:8\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tensor, device, dtype, nn\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mbnb\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GlobalOptimManager\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OutlierTracer, find_outlier_dims\n\u001B[1;32m     11\u001B[0m T \u001B[38;5;241m=\u001B[39m TypeVar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m\"\u001B[39m, bound\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.nn.Module\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/bitsandbytes/optim/__init__.py:6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# This source code is licensed under the MIT license found in the\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbitsandbytes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m COMPILED_WITH_CUDA\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madagrad\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01madam\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "File \u001B[0;32m~/Projects/fmrai/.venv/lib/python3.11/site-packages/bitsandbytes/cextension.py:20\u001B[0m\n\u001B[1;32m     18\u001B[0m     CUDASetup\u001B[38;5;241m.\u001B[39mget_instance()\u001B[38;5;241m.\u001B[39mgenerate_instructions()\n\u001B[1;32m     19\u001B[0m     CUDASetup\u001B[38;5;241m.\u001B[39mget_instance()\u001B[38;5;241m.\u001B[39mprint_log_stack()\n\u001B[0;32m---> 20\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001B[39m\n\u001B[1;32m     22\u001B[0m \n\u001B[1;32m     23\u001B[0m \u001B[38;5;124m    python -m bitsandbytes\u001B[39m\n\u001B[1;32m     24\u001B[0m \n\u001B[1;32m     25\u001B[0m \u001B[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001B[39m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001B[39m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001B[39m\u001B[38;5;124m'''\u001B[39m)\n\u001B[1;32m     28\u001B[0m lib\u001B[38;5;241m.\u001B[39mcadam32bit_grad_fp32 \u001B[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001B[39;00m\n\u001B[1;32m     29\u001B[0m lib\u001B[38;5;241m.\u001B[39mget_context\u001B[38;5;241m.\u001B[39mrestype \u001B[38;5;241m=\u001B[39m ct\u001B[38;5;241m.\u001B[39mc_void_p\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name_or_path = \"TheBloke/CodeLlama-7B-GPTQ\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"main\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map='cpu',\n",
    "                                             trust_remote_code=True,\n",
    "                                             revision=\"main\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:21:54.241956368Z",
     "start_time": "2023-10-14T06:21:53.154121847Z"
    }
   },
   "id": "c47180ffd3ddbabb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:21:37.369309941Z",
     "start_time": "2023-10-14T06:21:37.355141896Z"
    }
   },
   "id": "259df5077086f66f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\r\n",
      "  Downloading optimum-1.13.2.tar.gz (300 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m301.0/301.0 kB\u001B[0m \u001B[31m964.9 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting coloredlogs (from optimum)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: sympy in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from optimum) (1.12)\r\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from optimum) (4.34.0)\r\n",
      "Requirement already satisfied: torch>=1.9 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from optimum) (2.0.1+cu118)\r\n",
      "Requirement already satisfied: packaging in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from optimum) (23.1)\r\n",
      "Requirement already satisfied: numpy in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from optimum) (1.25.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from optimum) (0.16.4)\r\n",
      "Requirement already satisfied: datasets in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from optimum) (2.14.5)\r\n",
      "Requirement already satisfied: filelock in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (3.12.4)\r\n",
      "Requirement already satisfied: fsspec in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (2023.6.0)\r\n",
      "Requirement already satisfied: requests in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (4.8.0)\r\n",
      "Requirement already satisfied: networkx in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.9->optimum) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.9->optimum) (3.1.2)\r\n",
      "Requirement already satisfied: triton==2.0.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from torch>=1.9->optimum) (2.0.0)\r\n",
      "Requirement already satisfied: cmake in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.9->optimum) (3.25.0)\r\n",
      "Requirement already satisfied: lit in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.9->optimum) (15.0.7)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2023.10.3)\r\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.14.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.3.3)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\r\n",
      "Collecting protobuf (from transformers[sentencepiece]>=4.26.0->optimum)\r\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/c8/2c/03046cac73f46bfe98fc846ef629cf4f84c2f59258216aa2cc0d22bfca8f/protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pyarrow>=8.0.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->optimum) (13.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->optimum) (0.3.7)\r\n",
      "Requirement already satisfied: pandas in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->optimum) (2.1.1)\r\n",
      "Requirement already satisfied: xxhash in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->optimum) (3.3.0)\r\n",
      "Requirement already satisfied: multiprocess in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->optimum) (0.70.15)\r\n",
      "Requirement already satisfied: aiohttp in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from datasets->optimum) (3.8.5)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from sympy->optimum) (1.3.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (1.3.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.0.5)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from pandas->datasets->optimum) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from pandas->datasets->optimum) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from pandas->datasets->optimum) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/jacob/Projects/fmrai/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\r\n",
      "Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m311.6/311.6 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: optimum\r\n",
      "  Building wheel for optimum (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=6eee6f373719bc84aaca72d71337f69924b1944aa783c740a8c66ec7296b3168\r\n",
      "  Stored in directory: /home/jacob/.cache/pip/wheels/c7/36/5c/712f2d963d6d312afee816293b58610a3442d1a1de2182e651\r\n",
      "Successfully built optimum\r\n",
      "Installing collected packages: protobuf, humanfriendly, coloredlogs, optimum\r\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.13.2 protobuf-4.24.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install optimum"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T06:21:03.753876572Z",
     "start_time": "2023-10-14T06:20:54.343036419Z"
    }
   },
   "id": "3b41d07f9bcb051c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51c4a23b256aae85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
